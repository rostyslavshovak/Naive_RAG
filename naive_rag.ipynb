{
 "cells": [
  {
   "cell_type": "code",
   "id": "8600c539f0e62d0a",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T23:26:27.571171Z",
     "start_time": "2024-12-10T23:26:27.562798Z"
    }
   },
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:25:58.299685Z",
     "start_time": "2024-12-10T23:25:42.861306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pdf_path = \"C:/Users/Admin/Desktop/ammazon_annual.pdf\"\n",
    "documents = []\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text() or \"\"\n",
    "        # If tables exist and you want to incorporate them:\n",
    "        tables = page.extract_tables()\n",
    "        for table in tables:\n",
    "            table_text = \"\\n\".join([\", \".join(row) for row in table])\n",
    "            text += \"\\n\" + table_text\n",
    "        if text.strip():\n",
    "            documents.append(Document(page_content=text))"
   ],
   "id": "e06c340401168c5d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:26:39.127384Z",
     "start_time": "2024-12-10T23:26:31.400127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_text(text: str) -> str:          #tokenize, convert to lovercase, remove whitespace\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip().lower() for sent in doc.sents]\n",
    "    return ' '.join(sentences)\n",
    "\n",
    "#preprocess all documents\n",
    "for doc in documents:\n",
    "    original_text = doc.page_content\n",
    "    processed_text = preprocess_text(original_text)\n",
    "    doc.page_content = processed_text\n",
    "\n",
    "logger.info(\"Preprocessing of text completed.\")"
   ],
   "id": "eb110348057abd3e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing of text completed.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:42:02.826667Z",
     "start_time": "2024-12-10T23:42:02.775449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "logger.info(f\"Split documents into {len(docs)} chunks.\")"
   ],
   "id": "4b5dc18180b06f8b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Split documents into 1535 chunks.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:42:20.610237Z",
     "start_time": "2024-12-10T23:42:05.119728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "logger.info(f\"Loaded HuggingFace Embeddings model: {embedding_model_name}\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ],
   "id": "19703688fe01f389",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:__main__:Loaded HuggingFace Embeddings model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:42:23.534590Z",
     "start_time": "2024-12-10T23:42:22.274076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "#truncation to avoid length errors\n",
    "llm_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    max_new_tokens=100,\n",
    "    min_length=20,\n",
    "    do_sample=True,\n",
    "    # temperature=0.7,\n",
    "    # top_p=0.9,\n",
    "    # top_k=200\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "logger.info(f\"Initialized HuggingFace pipeline with model: {model_name}\")"
   ],
   "id": "5b19539564b06c46",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "INFO:__main__:Initialized HuggingFace pipeline with model: google/flan-t5-base\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:42:24.773512Z",
     "start_time": "2024-12-10T23:42:24.675807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#prompt and QA Chain\n",
    "prompt_template = \"\"\"You are a helpful assistant. Using the following context, write a complete, well-structured sentence (or short paragraph) that answers the question in detail. If there is relevant information in the context, incorporate it into your answer. Be direct, accurate, and use a formal tone.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Please provide a detailed answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ],
   "id": "fc7d071129115c1c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:42:27.862373Z",
     "start_time": "2024-12-10T23:42:25.987246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"What position in the company does the Jeffrey P. Bezos takes and since what time?\"\n",
    "response = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])  #dictionary"
   ],
   "id": "92101571838cf394",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=100) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Jeff Roberts Bezos is the President and Chief Executive Officer of Amazon. Amazon.com was founded in 1994 as a company.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T23:42:55.694368Z",
     "start_time": "2024-12-10T23:42:53.942020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# question = input(\"Enter your question\")\n",
    "question = \"What position in the company does Jeffrey P. Bezos hold and since when?\"\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(question)\n",
    "retrieved_chunks = [doc.page_content for doc in retrieved_docs]\n",
    "\n",
    "response = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "answer = response[\"result\"]  #dictionary query and result\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"\\nRetrieved Chunks:\")\n",
    "for i, chunk in enumerate(retrieved_chunks, start=1):\n",
    "    print(f\"Chunk {i}:\\n{chunk}\\n{'-' * 40}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=100) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What position in the company does Jeffrey P. Bezos hold and since when?\n",
      "Answer: He is currently chairman of the board of Amazon. He is currently chairman of the board of amazon.com since may 1996.\n",
      "\n",
      "Retrieved Chunks:\n",
      "Chunk 1:\n",
      "and secretary from september 2012 to may 2014, and as vice president and associate general counsel for litigation and regulatory matters from april 2002\n",
      "until september 2012. board of directors\n",
      "name age position\n",
      "jeffrey p. bezos 56 president, chief executive officer, and chairman of the board\n",
      "----------------------------------------\n",
      "Chunk 2:\n",
      "and in the capacities indicated as of january 30, 2020. signature title\n",
      "/s/ jeffrey p. bezos\n",
      "jeffrey p. bezos chairman of the board, president, and chief executive officer (principal executive\n",
      "officer)\n",
      "/s/ brian t. olsavsky\n",
      "----------------------------------------\n",
      "Chunk 3:\n",
      "request. /s/ jeffrey p. bezos\n",
      "jeffrey p. bezos\n",
      "chairman and chief executive officer\n",
      "(principal executive officer) date: january 30, 2020\n",
      "----------------------------------------\n",
      "Chunk 4:\n",
      "jeffrey p. bezos. mr. bezos has been chairman of the board of amazon.com since founding it in 1994 and chief executive officer since may 1996. mr. bezos served as president of the company from founding until june 1999 and again from october 2000 to the present. jeffrey m. blackburn. mr. blackburn\n",
      "----------------------------------------\n",
      "Chunk 5:\n",
      "patricia q. stonesifer 63 former president and chief executive officer, martha’s table\n",
      "wendell p. weeks 60 chief executive officer, corning incorporated\n",
      "5\n",
      "jeffrey p. bezos, , 56, , president, chief executive officer, and chairman of the board\n",
      "andrew r. jassy, , 52, , ceo amazon web services\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
